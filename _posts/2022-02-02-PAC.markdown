---
layout: post
title: "ML Theory: PAC Learnability and VC Dimensions"
date: 2022-04-06 13:32:20 +0300
description: Youâ€™ll find this post in your `_posts` directory. Go ahead and edit it and re-build the site to see your changes. # Add post description (optional)
img: pac.jpg # Add image post (optional)
---

<strong>Multi-Class Classification Problem</strong>: Let's say, we have a domain $\mathcal{X}$ where each element $x = (x_{1}, x_{2}, \cdots, x_{k})$ is a $k$ size vector of features, a distribution $\mathcal{D}$ over $\mathcal{X}$, and a label set $\mathcal{Y} = \\{1, 2, \cdots, n\\}$ so that there exists a function $c: \mathcal{X} \rightarrow \mathcal{Y}$. But we do not have any knowledge of the true distribution $\mathcal{D}$ and the function $c$. But we do have a finite sample $S = ((x_{1}, y_{1}), (x_{2}, y_{2}), \cdots, (x_{m}, y_{m}))$ where each pair is an input output mapping from $\mathcal{X} \times \mathcal{Y}$, i.e., $c(x_{i}) = y_{i}$ and some prior knowledge of the problem at hand.   
This prior knowledge of the problem is represented by a set of hypotheses called the <strong>Hypothesis Class</strong> $\mathcal{H}$. Every hypothesis $h \in \mathcal{H}$ is a conjectured solution to estimating the function $c$. The original function $c$ in this case, is called a concept. We are trying to learn the concept $c$ and $h$ is what we think of $c$.      
With the same domain and distribution, we could have a different concept $\bar c$ to learn and all of these different choices of $f$ creates the <strong>Concept Class</strong> we are trying to learn.        

<strong>Generalization Risk</strong>: Given a hpyothesis $h \in \mathcal{H}$, a target concept $f$ in concept class $F$, and a distribution $\mathcal{D}$ over domain $\mathcal{X}$, then the generalization risk or generalization error or true error of the hypothesis $h$ is defined to be,   
<center>$ R(h) = Pr_{x ~ D} [h(x) \neq f(x)]$</center>    


<strong>Empirical Risk</strong>: Given a hpyothesis $h \in \mathcal{H}$, a target concept $f$ in concept class $F$, and a sample $S = ((x_{1}, y_{1}), (x_{2}, y_{2}), \cdots, (x_{m}, y_{m}))$, then the empirical risk of the hypothesis $h$ with respect to this sample $S$ is defined to be,
<center>$ R_{S}(h) = \frac{1}{m} \sum_{i = 1}^{m} \mathcal{I}\\{h(x_{i}) \neq c(x_{i})\\}$ </center>
